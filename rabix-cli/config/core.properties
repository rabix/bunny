backend.execution.directory=.
backend.embedded.types=LOCAL

executor.calculate_file_checksum=true
executor.checksum_algorithm=SHA1

# executor.permission.uid=1000
# executor.permission.gid=1000
executor.set_permissions=true

engine.delete_intermediary_files=false
engine.treat_inputs_as_intermediary=false
engine.set_resources=true

# Supported IN_MEMORY, EVENT_SOURCING and POSTGRES. DB parameters can be set in store.properties
engine.store=IN_MEMORY
gc.enabled=false

executor.resource_fitter_enabled=true

cache.enabled=true
cache.directory=rabix-cache

docker.enabled=true
docker.remove_containers=true
docker.host=unix:///var/run/docker.sock
docker.username=username
docker.password=password
docker.override.auth.enabled=false

#use a different docker client/implementation (eg udocker):
#executor.override.command=/usr/local/bin/docker run {{#volumes}}-v {{location}}:{{path}} {{/volumes}} -w {{workingDir}} {{#env}}-e "{{key}}={{value}}" {{/env}} {{image}} /bin/sh -c "{{#escape}}{{command}}{{/escape}}"

#use singularity to run docker executors:
#executor.override.command=echo \"Bootstrap: docker\nFrom: {{image}}\n\n%runscript\n\n  {{#escape}}{{command}}{{/escape}}\n\n%environment\n {{#env}}\n export  {{key}}={{#escape}}{{value}}{{/escape}};{{/env}}\" > /tmp/script-{{jobId}} && sudo singularity build ./container-{{jobId}} /tmp/script-{{jobId}} && singularity run {{#volumes}}--bind {{path}}:{{location}}  {{/volumes}} --pwd {{workingDir}}  ./container-{{jobId}}

#TES Backend Options
tes.client_scheme=http
tes.client_host=localhost
tes.client_port=8000
#http client timeouts below are in seconds
#tes.client_connect_timeout=60
#tes.client_read_timeout=60
#tes.client_write_timeout=60

#How many threads are available to run and poll TES tasks
#tes.task_thread_pool=50

#How many threads are available to handle the postprocessing of complete tasks
#tes.postprocessing_thread_pool=1

#Url to the storage folder, supports file:// gs:// and s3:// urls
#if gs is used, authentication is taken from the environment
#for s3 the following keys should be added to a config file: s3.access_key, s3.secret_key

#tes.storage_base=s3://endpoint/bucket/folder

#S3 options.
#Format: s3.<provider_name>.<option>
#The provider name is used to group the options so its value is not important.
#Timeouts are in milliseconds.

#s3.amazon.endpoints=s3://s3.amazonaws.com, s3://s3.us-east-1.amazonaws.com, s3://s3.us-east-2.amazonaws.com, s3://s3.us-west-1.amazonaws.com, s3://s3.us-west-2.amazonaws.com
#s3.amazon.protocol=HTTPS
#s3.amazon.access_key=***************************
#s3.amazon.secret_key=****************************************
#s3.amazon.max_retry_error=10
#s3.amazon.connection_timeout=50000
#s3.amazon.max_connections=50
#s3.amazon.socket_timeout=50000
#s3.amazon.signer_override=AWS4SignerType
#s3.amazon.path_style_access=false
#
#s3.ceph.endpoints=s3://cephhost:8888/
#s3.ceph.protocol=HTTP
#s3.ceph.access_key=***************************
#s3.ceph.secret_key=****************************************
#s3.ceph.path_style_access=true
#s3.ceph.signer_override=S3SignerType
